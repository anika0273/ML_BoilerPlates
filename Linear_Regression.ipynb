{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c20ed13-d1e9-4fac-9508-3cb4ecbd7b77",
   "metadata": {},
   "source": [
    "# Machine Learning Boilerplate Workflow (Linear Regression Example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f289aa7-6980-4b25-bcc8-656e97750b5a",
   "metadata": {},
   "source": [
    "## 1. Define Problem\n",
    "\n",
    "We want to predict disease progression one year after baseline for diabetes patients.\n",
    "\n",
    "1. Target (y): a continuous value (disease progression measure).\n",
    "2. Features (X): 10 baseline medical variables (age, sex, BMI, blood pressure, and 6 blood serum measurements).\n",
    "3. Goal: Build an interpretable regression model to understand which features influence disease progression, and evaluate predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3555f8c-6bd9-4234-ada0-6565274cddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a49ad67-b51d-4e92-8d61-468eab14291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6475c3-617c-44c5-bea0-4425edc66636",
   "metadata": {},
   "source": [
    "## 2. Load and Inspect data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3b4786-97e7-42b5-9fab-c2ce40e2291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74250f47-eb6c-49b8-af66-3d12c2b4ac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and missing values\n",
    "print(X.info())\n",
    "print(\"Missing values:\\n\", X.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f12102-9060-4fed-8647-db5c9d10a193",
   "metadata": {},
   "source": [
    "ðŸ”¹ Other methods to consider:\n",
    "\n",
    "- .nunique() to check unique values (categorical detection).\n",
    "- .duplicated().sum() to detect duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2922d467-8f75-46c1-a9ac-fb8213adb4d3",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Why? To understand patterns, correlations, and distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d48da89-a412-4c77-acfe-cd3281c97a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Summary statistics\n",
    "display(X.describe())\n",
    "\n",
    "# Target distribution\n",
    "sns.histplot(y, bins=20, kde=True)\n",
    "plt.title(\"Distribution of Target (Disease Progression)\")\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(X.corr(), annot=False, cmap=\"coolwarm\")\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e0ee80-fade-4d90-8c71-9051c17f60f3",
   "metadata": {},
   "source": [
    "## 4. Data Preparation\n",
    "\n",
    "1. Scale not strictly required for linear regression, but helps with interpretation & regularization.\n",
    "2. Always split data into train/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae81a3b-5736-422f-ae8d-3d77c0391d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e568cc6-a5f1-4b91-9758-e42dcba6d594",
   "metadata": {},
   "source": [
    "## 5. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b75b0e8-ead8-4f98-824f-98ca0e8ac6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = linreg.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6df6e25-e88d-4fce-b2c2-e6124d6efee7",
   "metadata": {},
   "source": [
    "## 6. Gradient Descent (Conceptual Demo)\n",
    "\n",
    "Sklearn uses the Normal Equation (analytical). Letâ€™s demo gradient descent with 1 feature to illustrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fd9d90-1667-4dd3-a4c5-d591525bc32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Use BMI only for demo\n",
    "X_simple = X_train_scaled[:,2].reshape(-1,1)  \n",
    "y_simple = y_train.values.reshape(-1,1)\n",
    "\n",
    "def gradient_descent(X, y, lr=0.1, epochs=100):\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros((n,1))\n",
    "    losses = []\n",
    "    for _ in range(epochs):\n",
    "        gradients = -(2/m) * X.T.dot(y - X.dot(theta))\n",
    "        theta -= lr * gradients\n",
    "        loss = np.mean((y - X.dot(theta))**2)\n",
    "        losses.append(loss)\n",
    "    return theta, losses\n",
    "\n",
    "theta, losses = gradient_descent(X_simple, y_simple, lr=0.1, epochs=100)\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.title(\"Gradient Descent Convergence (MSE)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a41355-bd0a-4349-ac98-0a3584dddb8b",
   "metadata": {},
   "source": [
    "## 7. Evaluate Model (Regression Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec813d8-75ea-4ba3-82f0-3a0eb9e43545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(\"RÂ²:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438dd7a2-ab98-4e12-9353-1706d67187ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coefficients, p-values, log-likelihood using statsmodels:\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X_train_sm = sm.add_constant(X_train_scaled)\n",
    "model_sm = sm.OLS(y_train, X_train_sm).fit()\n",
    "print(model_sm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f46512-7b18-4de6-9371-628a9b241e98",
   "metadata": {},
   "source": [
    "## 8. Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50924951-33fc-4a03-afa5-bae28dfa6e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(linreg, X, y, cv=5, scoring=\"r2\")\n",
    "print(\"Cross-validated RÂ²:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d779bb93-30a6-4720-a595-c2450bf1a1fa",
   "metadata": {},
   "source": [
    "## 9. Regularization & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1267d7d-b16e-4f32-b5c2-44c9fab63b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Ridge\n",
    "ridge = Ridge()\n",
    "param_grid = {\"alpha\": [0.01, 0.1, 1, 10, 100]}\n",
    "ridge_grid = GridSearchCV(ridge, param_grid, cv=5, scoring=\"r2\")\n",
    "ridge_grid.fit(X_train_scaled, y_train)\n",
    "print(\"Best Ridge alpha:\", ridge_grid.best_params_)\n",
    "\n",
    "# Lasso\n",
    "lasso = Lasso()\n",
    "lasso_grid = GridSearchCV(lasso, param_grid, cv=5, scoring=\"r2\")\n",
    "lasso_grid.fit(X_train_scaled, y_train)\n",
    "print(\"Best Lasso alpha:\", lasso_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946b1d27-e35e-417d-b90f-1467cbeba909",
   "metadata": {},
   "source": [
    "## 10. (Optional) Classification-style Metrics\n",
    "\n",
    "Convert regression output to classification (high vs low progression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3061f3a-09ed-4cb1-9a21-60e6a79de6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Binarize target\n",
    "median_val = np.median(y)\n",
    "y_class = (y > median_val).astype(int)\n",
    "\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X, y_class, test_size=0.2, random_state=42)\n",
    "\n",
    "linreg_c = LinearRegression()\n",
    "linreg_c.fit(X_train_c, y_train_c)\n",
    "y_pred_prob = linreg_c.predict(X_test_c)\n",
    "\n",
    "y_pred_class = (y_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_test_c, y_pred_class)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_c, y_pred_class))\n",
    "print(\"Precision:\", precision_score(y_test_c, y_pred_class))\n",
    "print(\"Recall (Sensitivity):\", recall_score(y_test_c, y_pred_class))\n",
    "print(\"F1:\", f1_score(y_test_c, y_pred_class))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test_c, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label=f\"AUC={roc_auc:.2f}\")\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309f4637-acb9-4962-85bf-0668533ddc62",
   "metadata": {},
   "source": [
    "## 11. Bias-Variance Tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551208d1-aae2-473b-bdfb-10e40297f499",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors, test_errors = [], []\n",
    "for d in range(1, 11):\n",
    "    poly = np.vander(X_simple.flatten(), N=d, increasing=True)\n",
    "    model = LinearRegression().fit(poly, y_simple)\n",
    "    train_errors.append(mean_squared_error(y_simple, model.predict(poly)))\n",
    "    \n",
    "    test_poly = np.vander(X_test_scaled[:,2], N=d, increasing=True)\n",
    "    test_errors.append(mean_squared_error(y_test, model.predict(test_poly)))\n",
    "\n",
    "plt.plot(range(1,11), train_errors, label=\"Train Error\")\n",
    "plt.plot(range(1,11), test_errors, label=\"Test Error\")\n",
    "plt.xlabel(\"Polynomial Degree\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"Bias-Variance Tradeoff\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db4c6ff-7035-40eb-a2c7-e4ee9f0820c8",
   "metadata": {},
   "source": [
    "## 12. Interpret Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16203bd-80d1-487d-9e84-28a250054d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    \"Feature\": X.columns,\n",
    "    \"Coefficient\": linreg.coef_\n",
    "}).sort_values(by=\"Coefficient\", ascending=False)\n",
    "\n",
    "print(coef_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac95c20b-3bc7-4f9b-82e5-b99e42e532eb",
   "metadata": {},
   "source": [
    "## 13. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f04878a-bdae-4fbe-9874-dc2838b61ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(linreg, \"linear_model.pkl\")\n",
    "print(\"Model saved as linear_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33434713-814c-4cad-a234-c9392fe3fc7f",
   "metadata": {},
   "source": [
    "# NOTE:\n",
    "\n",
    "In the code I shared for the Diabetes dataset, hereâ€™s what happened:\n",
    "\n",
    "- The basic Linear Regression model in sklearn (LinearRegression) does not require explicit standardization, because it estimates coefficients using Ordinary Least Squares (OLS). The scale of features doesnâ€™t affect predictions, but it does affect coefficient interpretation (larger-scaled features dominate).\n",
    "\n",
    "- When I showed Ridge regression / Lasso for regularization & hyperparameter tuning, I did standardize the data using StandardScaler(). This is necessary because regularization penalizes coefficients, and without standardization, features with larger scales get penalized more unfairly.\n",
    "\n",
    "- For gradient descent demonstration, I normalized values internally when plotting, but I didnâ€™t explicitly run a scaler on the main regression data â€” because that part was just illustrative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc91606d-4a17-424b-9a41-1295ac140817",
   "metadata": {},
   "source": [
    "# NOTE:\n",
    "\n",
    "ðŸ‘‰ Best Practice (checklist correction):\n",
    "\n",
    "Always standardize features when:\n",
    "\n",
    "Using algorithms that are scale-sensitive (regularization, gradient descent, SVM, kNN, PCA, etc.)\n",
    "\n",
    "You need interpretable coefficients (so you can compare their relative magnitudes).\n",
    "\n",
    "For plain OLS (unregularized LinearRegression), scaling isnâ€™t strictly required, but itâ€™s often done anyway for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5315abf-e950-4462-8fa3-6a80c8a0d02d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
