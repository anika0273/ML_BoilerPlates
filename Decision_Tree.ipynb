{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58433f8b-e7b6-4d67-8590-940a952c31be",
   "metadata": {},
   "source": [
    "# Machine Learning Boilerplate Workflow (Decision Tree Example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63b2103-0987-4d09-85b9-4c585dc62ab1",
   "metadata": {},
   "source": [
    "## 1. Define Problem\n",
    "- Goal: Predict if a tumor is malignant (0) or benign (1) based on clinical features.\n",
    "- Decision Trees are intuitive \"if-else\" models but prone to overfitting.\n",
    "- Ensembles (Random Forest, Boosting) help improve generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae7b609-4ad1-4939-8448-39ba612582e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "# Models\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import (\n",
    "RandomForestClassifier, ExtraTreesClassifier,\n",
    "AdaBoostClassifier, GradientBoostingClassifier,\n",
    "StackingClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Advanced libraries\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca51b80-78e3-42af-96ec-fcc9ca0d2cde",
   "metadata": {},
   "source": [
    "## 2. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb75934-c21e-4451-83b6-1cf4759d4c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n",
    "\n",
    "\n",
    "print(\"Dataset shape:\", X.shape)\n",
    "print(\"Target distribution:\\n\", y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eb0390-df6f-4952-8421-1674be2030e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.describe().T.head())  # summary statistics\n",
    "sns.countplot(x=y)\n",
    "plt.title(\"Target Distribution: 0=Malignant, 1=Benign\")\n",
    "plt.show()\n",
    "\n",
    "# Quick correlation heatmap (to see redundancy)\n",
    "sns.heatmap(X.corr(), cmap=\"coolwarm\", cbar=False)\n",
    "plt.title(\"Feature Correlations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f76a78-8d09-4d4f-b8ef-2688b7ac9894",
   "metadata": {},
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ec7282-b5ba-4bf7-8d9c-d61a29ae7677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0810d067-90bc-4dcd-8173-7ed66e3d2da4",
   "metadata": {},
   "source": [
    "## 4.1 Baseline Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d52d7b-0a30-4d7c-86de-ccd1cccf224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Decision Tree ---\")\n",
    "dt = DecisionTreeClassifier(criterion=\"gini\", random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "print(\"Accuracy:\", dt.score(X_test, y_test))\n",
    "\n",
    "\n",
    "# Visualize tree (small depth for clarity)\n",
    "small_dt = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "small_dt.fit(X_train, y_train)\n",
    "plt.figure(figsize=(12,6))\n",
    "plot_tree(small_dt, feature_names=X.columns, class_names=data.target_names, filled=True)\n",
    "plt.title(\"Decision Tree (max_depth=3)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533a9f5b-a34d-45b6-9862-cd8f1de418cb",
   "metadata": {},
   "source": [
    "## 4.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52802a8-6ed7-471d-94ab-78ea2d18654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Random Forest ---\")\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "print(\"Accuracy:\", rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8b1161-0aef-4640-829d-a22106336ca8",
   "metadata": {},
   "source": [
    "## 4.3 Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e127b1-207d-4447-a4e6-f2c370c6df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Extra Trees ---\")\n",
    "et = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "et.fit(X_train, y_train)\n",
    "print(\"Accuracy:\", et.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45abb47e-7df4-4e32-98f9-7cd3d1bb9e0c",
   "metadata": {},
   "source": [
    "## 4.4 AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d123ed5c-9bf1-4ed0-b8b9-a613af4c5fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- AdaBoost ---\")\n",
    "ab = AdaBoostClassifier(n_estimators=100, learning_rate=0.5, random_state=42)\n",
    "ab.fit(X_train, y_train)\n",
    "print(\"Accuracy:\", ab.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1563bd-feb6-44f7-8684-f73b75f42b40",
   "metadata": {},
   "source": [
    "## 4.5 Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e63c95-ca72-4777-b68d-ea7efe0a8451",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Gradient Boosting ---\")\n",
    "gb = GradientBoostingClassifier(n_estimators=200, learning_rate=0.05, max_depth=3, random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "print(\"Accuracy:\", gb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4acd5f-b5a7-49a2-86d8-1c3f718c82b8",
   "metadata": {},
   "source": [
    "## 4.6 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cc64fc-8198-4c72-a586-3bce6f625fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- XGBoost ---\")\n",
    "xgb = XGBClassifier(n_estimators=200, learning_rate=0.05, max_depth=3,\n",
    "subsample=0.8, colsample_bytree=0.8, eval_metric=\"logloss\", random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "print(\"Accuracy:\", xgb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f3340d-4e3e-46b6-868f-d6c1cab74f95",
   "metadata": {},
   "source": [
    "## 4.7 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3fcb9c-ba8a-4392-9e68-e69d6fb2c799",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- LightGBM ---\")\n",
    "lgbm = LGBMClassifier(n_estimators=200, learning_rate=0.05, random_state=42)\n",
    "lgbm.fit(X_train, y_train)\n",
    "print(\"Accuracy:\", lgbm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc7368f-2ca3-4ecf-912d-e706b15bf5d3",
   "metadata": {},
   "source": [
    "## 4.8 CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7107d27-b6ee-49a9-a536-3af57fd53a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- CatBoost ---\")\n",
    "cat = CatBoostClassifier(iterations=200, learning_rate=0.05, depth=6, verbose=0, random_state=42)\n",
    "cat.fit(X_train, y_train)\n",
    "print(\"Accuracy:\", cat.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488936c4-d792-45de-9194-8db3e379a79b",
   "metadata": {},
   "source": [
    "## 4.9 Stacking (Ensemble of Ensembles) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7da6793-5b77-4994-9056-cfb6a123b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Stacking ---\")\n",
    "stack = StackingClassifier(\n",
    "estimators=[\n",
    "('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "('xgb', XGBClassifier(eval_metric=\"logloss\", random_state=42))\n",
    "],\n",
    "final_estimator=LogisticRegression(max_iter=1000)\n",
    ")\n",
    "stack.fit(X_train, y_train)\n",
    "print(\"Accuracy:\", stack.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a843c888-b22f-44ec-ac5a-b1dfd8676153",
   "metadata": {},
   "source": [
    "# All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a694078c-7c60-4c8f-8882-43dad2951221",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "\"Decision Tree\": DecisionTreeClassifier(criterion=\"gini\", random_state=42),\n",
    "\"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "\"Extra Trees\": ExtraTreesClassifier(n_estimators=100, random_state=42),\n",
    "\"AdaBoost\": AdaBoostClassifier(n_estimators=100, learning_rate=0.5, random_state=42),\n",
    "\"Gradient Boosting\": GradientBoostingClassifier(n_estimators=200, learning_rate=0.05, max_depth=3, random_state=42),\n",
    "\"XGBoost\": XGBClassifier(n_estimators=200, learning_rate=0.05, max_depth=3, subsample=0.8, colsample_bytree=0.8, eval_metric=\"logloss\", random_state=42),\n",
    "\"LightGBM\": LGBMClassifier(n_estimators=200, learning_rate=0.05, random_state=42),\n",
    "\"CatBoost\": CatBoostClassifier(iterations=200, learning_rate=0.05, depth=6, verbose=0, random_state=42),\n",
    "\"Stacking\": StackingClassifier(\n",
    "estimators=[\n",
    "('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "('xgb', XGBClassifier(eval_metric=\"logloss\", random_state=42))\n",
    "],\n",
    "final_estimator=LogisticRegression(max_iter=1000)\n",
    ")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062745a9-276e-495d-b36a-ddeadd7e449f",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3b83e0-8920-4649-a098-9b8af8eac400",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_models = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    model.fit(X_train, y_train)\n",
    "    acc = model.score(X_test, y_test)\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    fitted_models[name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091b3967-17f4-4b9d-bbba-1145c625cb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation (Confusion Matrix, Report, ROC for all models)\n",
    "plt.figure(figsize=(8,6))\n",
    "for name, model in fitted_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_probs = model.predict_proba(X_test)[:,1]\n",
    "    # Confusion Matrix (example: Random Forest only for visualization)\n",
    "    if name == \"Random Forest\":\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.title(\"Confusion Matrix (Random Forest)\")\n",
    "        plt.show()\n",
    "        print(f\"Classification Report ({name}):\\n\", classification_report(y_test, y_pred))\n",
    "    \n",
    "    \n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
    "    auc = roc_auc_score(y_test, y_probs)\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC={auc:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc37f28-7fc0-486b-8d1d-ef7dd3736821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC for all models\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves Across Models\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514e018b-97f3-447e-b7d0-e1aaa2c4a801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 4: Feature Importances (example: Random Forest) ---\n",
    "importances = pd.Series(fitted_models[\"Random Forest\"].feature_importances_, index=X.columns)\n",
    "importances.sort_values(ascending=False).head(10).plot(kind=\"barh\")\n",
    "plt.title(\"Top 10 Feature Importances (Random Forest)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebdaef6-71b5-484c-b7fa-f5a28a62b657",
   "metadata": {},
   "source": [
    "## 6. Overfitting & Pruning\n",
    "- Trees can perfectly memorize data (overfit).\n",
    "- Solution: Limit depth, min_samples, or use Cost Complexity Pruning (ccp_alpha).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad1185b-e993-42a7-a796-d3f979b0a83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = dt.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "train_scores, test_scores = [], []\n",
    "for alpha in ccp_alphas:\n",
    "    clf = DecisionTreeClassifier(random_state=42, ccp_alpha=alpha)\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_scores.append(clf.score(X_train, y_train))\n",
    "    test_scores.append(clf.score(X_test, y_test))\n",
    "\n",
    "plt.plot(ccp_alphas, train_scores, marker='o', label=\"Train\")\n",
    "plt.plot(ccp_alphas, test_scores, marker='o', label=\"Test\")\n",
    "plt.xlabel(\"Alpha (Pruning Strength)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Cost-Complexity Pruning Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209fbc25-cfca-4c53-aa2b-52cbad5f8686",
   "metadata": {},
   "source": [
    "## 7. Random Forest (Bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a26cd80-f784-4e02-9ba2-2a0eb603b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Random Forest Test Accuracy:\", rf.score(X_test, y_test))\n",
    "\n",
    "# Feature importance\n",
    "feat_importance = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "feat_importance.nlargest(10).plot(kind=\"barh\")\n",
    "plt.title(\"Top 10 Feature Importances (Random Forest)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15d5f86-1c26-411e-ab74-639a566d8c6d",
   "metadata": {},
   "source": [
    "## 8. Boosting (AdaBoost & Gradient Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbf865a-9862-4ac3-b78e-749038253ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "ada = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "ada.fit(X_train, y_train)\n",
    "print(\"AdaBoost Test Accuracy:\", ada.score(X_test, y_test))\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "print(\"Gradient Boosting Test Accuracy:\", gb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edaa19c-6458-4dce-b433-68af254b4e4e",
   "metadata": {},
   "source": [
    "## 9. Bias-Variance Tradeoff (Learning Curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf765f6-cdb6-432c-911a-32d496f3d1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    dt, X_train, y_train, cv=5, scoring=\"accuracy\"\n",
    ")\n",
    "train_mean, test_mean = np.mean(train_scores, axis=1), np.mean(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean, label=\"Training\")\n",
    "plt.plot(train_sizes, test_mean, label=\"Validation\")\n",
    "plt.xlabel(\"Training Examples\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Decision Tree Bias-Variance Tradeoff\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6bbe94-8477-46e5-b1a1-114179bad13a",
   "metadata": {},
   "source": [
    "## 10. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae43661a-b167-4b76-a645-3cd18d1434e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(fitted_models[\"Random Forest\"], \"random_forest_breast_cancer.pkl\")\n",
    "print(\"Random Forest model saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
